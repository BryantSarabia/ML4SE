{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification\n",
    "\n",
    "## Multi-Label Classification of Wikipedia Comments\n",
    "\n",
    "This notebook implements machine learning and deep learning approaches for toxic comment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data.loader import FileBasedDataLoader\n",
    "from src.data.preprocessor import TextPreprocessor\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = FileBasedDataLoader(data_dir='../data')\n",
    "X_train, y_train = loader.load_train_data()\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Label columns: {y_train.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(X_train.head())\n",
    "display(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "### 2.1 Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = y_train.sum().sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "label_counts.plot(kind='barh', color='coral')\n",
    "plt.xlabel('Number of Comments')\n",
    "plt.ylabel('Label')\n",
    "plt.title('Distribution of Toxicity Labels in Training Data')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../report/figures/label_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLabel Statistics:\")\n",
    "for label in label_counts.index:\n",
    "    count = label_counts[label]\n",
    "    percentage = (count / len(y_train)) * 100\n",
    "    print(f\"{label:15s}: {count:6d} ({percentage:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Multi-Label Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_per_comment = y_train.sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "labels_per_comment.value_counts().sort_index().plot(kind='bar', color='steelblue')\n",
    "plt.xlabel('Number of Labels')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.title('Distribution of Label Count per Comment')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../report/figures/multilabel_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMulti-Label Statistics:\")\n",
    "for i in range(7):\n",
    "    count = (labels_per_comment == i).sum()\n",
    "    percentage = (count / len(y_train)) * 100\n",
    "    print(f\"{i} label(s): {count:6d} ({percentage:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Comment Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_lengths = X_train['comment_text'].str.len()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(comment_lengths, bins=50, color='green', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Character Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Comment Lengths (Characters)')\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "word_counts = X_train['comment_text'].str.split().str.len()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(word_counts, bins=50, color='purple', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Comment Lengths (Words)')\n",
    "plt.xlim(0, 400)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../report/figures/comment_length_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nComment Length Statistics (characters):\")\n",
    "print(comment_lengths.describe())\n",
    "print(f\"\\nComment Length Statistics (words):\")\n",
    "print(word_counts.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Label Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = y_train.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Toxicity Labels')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../report/figures/label_correlation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor(remove_stopwords=True, use_lemmatization=False)\n",
    "\n",
    "sample_texts = [\n",
    "    \"I can't believe you're so stupid!\",\n",
    "    \"This is a clean comment about the article.\",\n",
    "    \"You're an idiot and shouldn't be allowed here!!!\"\n",
    "]\n",
    "\n",
    "print(\"Sample Text Preprocessing:\\n\")\n",
    "for text in sample_texts:\n",
    "    cleaned = preprocessor.clean_text(text)\n",
    "    print(f\"Original: {text}\")\n",
    "    print(f\"Cleaned:  {cleaned}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Word Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing text for word frequency analysis...\")\n",
    "cleaned_comments = preprocessor.preprocess_batch(X_train['comment_text'].head(10000).tolist())\n",
    "\n",
    "all_words = []\n",
    "for comment in cleaned_comments:\n",
    "    all_words.extend(comment.split())\n",
    "\n",
    "word_freq = Counter(all_words)\n",
    "most_common = word_freq.most_common(20)\n",
    "\n",
    "words, counts = zip(*most_common)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(words, counts, color='teal')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 20 Most Frequent Words (after preprocessing)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../report/figures/word_frequency.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal unique words: {len(word_freq)}\")\n",
    "print(f\"Total words: {len(all_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "- Implement baseline models (TF-IDF + Logistic Regression, Naive Bayes)\n",
    "- Implement deep learning model (BiLSTM)\n",
    "- K-fold cross-validation\n",
    "- Model comparison and evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
